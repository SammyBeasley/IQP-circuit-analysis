{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IQP circuits to investigate n-node connected graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to import all the packages\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import itertools\n",
    "from sympy import fwht\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict, Counter\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to generate and plot all n-node graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is probably not the most efficent way to generate all non-isomorphic graphs but it only need to be run once\n",
    "def generate_all_connected_graphs(n):\n",
    "    nodes = list(range(n))\n",
    "    all_possible_edges = list(combinations(nodes, 2))\n",
    "    connected_graphs = []\n",
    "\n",
    "    for i in range(1, 2 ** len(all_possible_edges)):\n",
    "        edge_indices = [j for j in range(len(all_possible_edges)) if (i >> j) & 1]\n",
    "        edges = [all_possible_edges[j] for j in edge_indices]\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(nodes)\n",
    "        G.add_edges_from(edges)\n",
    "        if nx.is_connected(G):\n",
    "            if not any(nx.is_isomorphic(G, H) for H in connected_graphs):\n",
    "                connected_graphs.append(G)\n",
    "    return connected_graphs\n",
    "\n",
    "\n",
    "\n",
    "def plot_graphs(graphs):\n",
    "    n = len(graphs)\n",
    "    cols = math.floor(n**0.5) + 1\n",
    "    rows = (n // cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(3 * cols, 3 * rows))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n:\n",
    "            nx.draw(graphs[i], ax=ax, with_labels=True, node_color='lightblue', edge_color='gray')\n",
    "            ax.set_title(f\"Graph {i+1}\")\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all connected graphs for n nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the number of nodes and save/load the set of connected graphs generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file: n node connected graphs\\7-node connected graphs.pkl\n"
     ]
    }
   ],
   "source": [
    "# Set the number of nodes you want to look at\n",
    "n_nodes = 7\n",
    "\n",
    "\n",
    "# Create file directory\n",
    "folder = \"n node connected graphs\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "filename = os.path.join(folder, f\"{n_nodes}-node connected graphs.pkl\")\n",
    "\n",
    "\n",
    "# Try to load from file\n",
    "if os.path.exists(filename):\n",
    "    print(f\"Loading from file: {filename}\")\n",
    "    with open(filename, \"rb\") as f:\n",
    "        connected_graphs_n = pickle.load(f)\n",
    "else:\n",
    "    # Save\n",
    "    #generate data\n",
    "    connected_graphs_n = generate_all_connected_graphs(n_nodes)\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(connected_graphs_n, f)\n",
    "    print(f\"Saved to file: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Uncomment to plot all graphs\n",
    "# print(\"Plotting data...\")\n",
    "# plot_graphs(connected_graphs_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fuctions that create the IQP circuit and simulate the distribution for each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intermediate state before Hadamards\n",
    "def compute_amplitude_vector(G, n, theta):\n",
    "    state = np.zeros(2**n, dtype=complex)\n",
    "    \n",
    "    for x in range(2**n):\n",
    "        bitstring = np.array(list(np.binary_repr(x, width=n)), dtype=int)\n",
    "        phase = 0.0\n",
    "        for (j, k) in G.edges:\n",
    "            parity = (bitstring[j] + bitstring[k]) % 2\n",
    "            phase += (-1)**parity\n",
    "        amplitude = np.exp(1j * theta * phase) / np.sqrt(2**n)\n",
    "        state[x] = amplitude\n",
    "\n",
    "    return state\n",
    "\n",
    "# Simulate the IQP circuit\n",
    "def simulate_circuit(G, theta):\n",
    "    n = len(G.nodes)\n",
    "    intermediate_state = compute_amplitude_vector(G, n, theta)\n",
    "    final_state = fwht(intermediate_state.copy()) / np.sqrt(len(intermediate_state))  # Apply FWHT and normalise\n",
    "    probabilities = np.abs(final_state) ** 2\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate distributions for each n node graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating the distributions for each graph over a range of theta values with save/load for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulation code with save/load\n",
    "def generate_or_load_distributions(connected_graphs_n, n_nodes, thetas, filename=None):\n",
    "    if filename is None:\n",
    "        folder = \"IQP distributions for n nodes\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        filename = os.path.join(folder, f\"iqp_distributions_{n_nodes}nodes.pkl\")\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Loading distributions from {filename}...\")\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            return data['connected_graph_distributions'], data['thetas'], data['graph_labels']\n",
    "    else:\n",
    "        print(\"Generating distributions...\")\n",
    "\n",
    "        graph_labels = []\n",
    "        connected_graph_distributions = {}\n",
    "\n",
    "        # Simulate circuit for each theta value\n",
    "        for i, G in enumerate(connected_graphs_n):\n",
    "            graph_label = f\"G_{i+1}\"\n",
    "            graph_labels.append(graph_label)\n",
    "            connected_graph_distributions[graph_label] = [simulate_circuit(G, theta) for theta in thetas]\n",
    "\n",
    "        # Save to file\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'connected_graph_distributions': connected_graph_distributions,\n",
    "                'thetas': thetas,\n",
    "                'graph_labels': graph_labels,\n",
    "                'n_nodes': n_nodes\n",
    "            }, f)\n",
    "\n",
    "        return connected_graph_distributions, thetas, graph_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading distributions from IQP distributions for n nodes\\iqp_distributions_7nodes.pkl...\n"
     ]
    }
   ],
   "source": [
    "# Define theta range\n",
    "frames = 50\n",
    "thetas = np.linspace(0, np.pi / 2, frames)\n",
    "\n",
    "connected_graph_distributions, thetas, graph_labels = generate_or_load_distributions(connected_graphs_n, n_nodes, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for plotting bitstring proabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is used to compare and analyse distribtutions from specific graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Use to look at specific graphs\n",
    "def bit_reversed_indices(n):\n",
    "    \"\"\"Generate bit-reversed indices to spread colors apart.\"\"\"\n",
    "    width = int(np.ceil(np.log2(n)))\n",
    "    # Reverse the binary representation of each index to create a new ordering\n",
    "    return [int(f'{i:0{width}b}'[::-1], 2) for i in range(n)]\n",
    "\n",
    "\n",
    "def plot_connected_graphs_bitstring_probabilities(\n",
    "    connected_graph_distributions, \n",
    "    thetas, \n",
    "    n_nodes, \n",
    "    selected_graphs=None, \n",
    "    selected_bitstrings=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the probability of selected bitstrings for connected graphs as a function of θ.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    connected_graph_distributions : dict\n",
    "        Dictionary mapping graph labels (e.g., 'G_1') to their corresponding\n",
    "        probability distributions for each bitstring.\n",
    "        Each entry should be a 2D array of shape (len(thetas), 2**n_nodes).\n",
    "    thetas : array-like\n",
    "        Array of θ values used to generate the distributions.\n",
    "    n_nodes : int\n",
    "        Number of qubits/nodes in each graph.\n",
    "    selected_graphs : list of str, optional\n",
    "        List of graph labels to plot. Must match keys in connected_graph_distributions.\n",
    "        If None, all graphs are plotted.\n",
    "    selected_bitstrings : list of str, optional\n",
    "        List of bitstrings to plot. If None, all bitstrings are plotted.\n",
    "\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    - Graph labels must match keys in connected_graph_distributions, e.g. ['G_1', 'G_2'].\n",
    "    - Uses bit_reversed_indices(n) to spread colors to make graphs more distinct when plotting.\n",
    "    \"\"\"\n",
    "    all_bitstrings = [format(i, f'0{n_nodes}b') for i in range(2**n_nodes)]\n",
    "    bitstring_indices = {bs: i for i, bs in enumerate(all_bitstrings)}\n",
    "\n",
    "    # Use all graphs if none selected\n",
    "    if selected_graphs is None:\n",
    "        selected_graphs = list(connected_graph_distributions.keys())\n",
    "\n",
    "    # Use all bitstrings if none selected\n",
    "    if selected_bitstrings is None:\n",
    "        selected_bitstrings = all_bitstrings\n",
    "\n",
    "    # Make it a square layout\n",
    "    n_bitstrings = len(selected_bitstrings)\n",
    "    n_rows = int(np.ceil(np.sqrt(n_bitstrings)))\n",
    "    n_cols = int(np.ceil(n_bitstrings / n_rows))\n",
    "\n",
    "    # Create subplot grid\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 15), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Make graphs that are close together in number have distinct colours\n",
    "    cmap = plt.colormaps['hsv']\n",
    "    indices = bit_reversed_indices(len(selected_graphs))\n",
    "    colors = [cmap(i / len(selected_graphs)) for i in indices]\n",
    "\n",
    "    # Plot probability of each selected bitstring for each selected graph\n",
    "    for idx, graph_label in enumerate(selected_graphs):\n",
    "        probs = np.array(connected_graph_distributions[graph_label])\n",
    "        for i, bitstring in enumerate(selected_bitstrings):\n",
    "            bit_index = bitstring_indices[bitstring]\n",
    "            label = graph_label if i == 0 else None\n",
    "            axes[i].plot(thetas / np.pi, probs[:, bit_index], label=label, color=colors[idx])\n",
    "\n",
    "    # Set titles, labels, and limits for each subplot\n",
    "    for i, bitstring in enumerate(selected_bitstrings):\n",
    "        axes[i].set_title(bitstring)\n",
    "        axes[i].set_ylim(0, 1)\n",
    "        axes[i].set_xlabel(r'$2\\theta / \\pi$')\n",
    "        axes[i].set_ylabel('Probability')\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(n_bitstrings, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Add overall figure title and legend\n",
    "    fig.suptitle(rf\"{n_nodes}-Qubit Selected Bitstrings vs $\\theta$\", fontsize=20)\n",
    "    fig.legend(loc=\"center right\")\n",
    "    fig.tight_layout(rect=[0, 0, 0.95, 0.95])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all bitstring probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot\n",
    "\n",
    "#plot_connected_graphs_bitstring_probabilities(connected_graph_distributions, thetas, n_nodes, selected_graphs=None, selected_bitstrings=None)\n",
    "\n",
    "# Example comparing G_1 and G_2\n",
    "#plot_connected_graphs_bitstring_probabilities(connected_graph_distributions, thetas, n_nodes, selected_graphs=['G_1','G_2'], selected_bitstrings=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the graphs using different metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to compute each metric and generate the relevant similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity/distance/fidelitiy functions\n",
    "def similarity(p, q):\n",
    "    p = np.asarray(p, dtype=np.float64)\n",
    "    q = np.asarray(q, dtype=np.float64)\n",
    "    return (np.inner(p,q)/(np.linalg.norm(p)*np.linalg.norm(q)))\n",
    "\n",
    "def tvd(p, q):\n",
    "    return 0.5 * np.sum(np.abs(p - q))\n",
    "\n",
    "def fidelity(p, q):\n",
    "    p = np.asarray(p, dtype=np.float64)\n",
    "    q = np.asarray(q, dtype=np.float64)\n",
    "    return (np.sum(np.sqrt(p * q)))**2\n",
    "\n",
    "\n",
    "# Generate similarity matrices\n",
    "def compute_similarity_for_graph(g1_label, metric_func, graph_labels, thetas, connected_graph_distributions):\n",
    "    sim_matrix = np.zeros((len(graph_labels), len(thetas)))\n",
    "    for i, theta in enumerate(thetas):\n",
    "        p1 = connected_graph_distributions[g1_label][i]\n",
    "        for j, g2_label in enumerate(graph_labels):\n",
    "            p2 = connected_graph_distributions[g2_label][i]\n",
    "            sim_matrix[j, i] = metric_func(p1, p2)\n",
    "    return g1_label, sim_matrix\n",
    "\n",
    "# Function for doing this in parallel to speed up compute time.\n",
    "# This is especially needed for n_nodes > 5 due to the number of graphs.\n",
    "def compute_similarity_matrix_parallel(metric_func):\n",
    "    print('Computing similarity data in parallel...')\n",
    "    return dict(\n",
    "        Parallel(n_jobs=-1)(\n",
    "            delayed(compute_similarity_for_graph)(g1_label, metric_func, graph_labels, thetas, connected_graph_distributions)\n",
    "            for g1_label in graph_labels\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate date for your selected metric and save/load from file for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading similarity data from: n node similarity data\\7_node_similarity_data_metric_tvd.pkl\n"
     ]
    }
   ],
   "source": [
    "# Select metric\n",
    "metric = tvd # or similariy or fidelity\n",
    "\n",
    "folder = \"n node similarity data\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "metric_name = metric.__name__\n",
    "filename = os.path.join(folder, f\"{n_nodes}_node_similarity_data_metric_{metric_name}.pkl\")\n",
    "if os.path.exists(filename):\n",
    "    print(f\"Loading similarity data from: {filename}\")\n",
    "    with open(filename, \"rb\") as f:\n",
    "        similarity_data = pickle.load(f)\n",
    "else:\n",
    "    similarity_data = compute_similarity_matrix_parallel(metric)\n",
    "    print(f\"Saving similarity data for metric function = {metric_name}...\")\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(similarity_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_data(similarity_data):\n",
    "    # Configure plot\n",
    "    batch_size = 9                           # Number of graphs to show per batch of subplots\n",
    "    n_graphs = len(graph_labels)            \n",
    "    n_batches = math.ceil(n_graphs / batch_size)  # Number of batches needed to show all graphs\n",
    "\n",
    "    # Loop over each batch of graphs\n",
    "    for batch_idx in range(n_batches):\n",
    "        # Selecting the subset of graph labels for this batch\n",
    "        start = batch_idx * batch_size\n",
    "        end = min(start + batch_size, n_graphs) # This min is needed so that the last page formats correctly\n",
    "        batch_labels = graph_labels[start:end] # Slice out of the list of graph labels\n",
    "        \n",
    "        # Setup figure size\n",
    "        n_subplots = len(batch_labels)       \n",
    "        cols = 3                             \n",
    "        rows = math.ceil(n_subplots / cols) \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))\n",
    "\n",
    "        axes = axes.flatten() # For easy iteration\n",
    "\n",
    "        # Loop over each subplot position and corresponding graph label\n",
    "        for ax, g1_label in zip(axes, batch_labels):\n",
    "            sim_matrix = similarity_data[g1_label]\n",
    "\n",
    "            # Display similarity matrix as heatmap\n",
    "            heatmap = ax.imshow(\n",
    "                sim_matrix,\n",
    "                aspect='auto',                # Stretch to fill subplot space\n",
    "                origin='lower',               # Sets G_0 to be the bottom graph\n",
    "                cmap='magma_r',               \n",
    "                extent=[0, 1, 0, len(graph_labels)], \n",
    "                vmin=0, vmax=1                \n",
    "            )\n",
    "\n",
    "            # Set subplot title and axis labels\n",
    "            ax.set_title(g1_label, fontsize=12) \n",
    "            ax.set_yticks(np.arange(len(graph_labels)) + 0.5)  # Center the y labels\n",
    "            ax.set_yticklabels(graph_labels, fontsize=8)       # Show all graph labels up y axis\n",
    "            ax.set_xticks([0, 0.25, 0.5, 0.75, 1])            \n",
    "            ax.set_xticklabels(                               # LaTeX labels for x axis\n",
    "                [r'$0$', r'$\\frac{\\pi}{4}$', r'$\\frac{\\pi}{2}$',\n",
    "                r'$\\frac{3\\pi}{4}$', r'$\\pi$'],\n",
    "                fontsize=10\n",
    "            )\n",
    "            ax.set_xlabel(r'$\\theta$', fontsize=12)\n",
    "            ax.set_ylabel('Graphs', fontsize=12)\n",
    "\n",
    "            # Add an individual colorbar for this subplot\n",
    "            fig.colorbar(heatmap, ax=ax, orientation='vertical', pad=0.01, fraction=0.05)\n",
    "\n",
    "        # Hide any unused subplot axes (when batch has < rows*cols subplots)\n",
    "        for i in range(n_subplots, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        # Add a figure-wide title for the batch\n",
    "        fig.suptitle(\n",
    "            f'{metric.__name__} of probability distributions between {n_nodes}-vertex connected graphs\\n'\n",
    "            f'Batch {batch_idx + 1}/{n_batches}',\n",
    "            fontsize=16\n",
    "        )\n",
    "\n",
    "        # Adjust layout so titles/labels don’t overlap and leave space for page title\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot data:\n",
    "\n",
    "#plot_similarity_data(similarity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating custom graphs for checking isomorphisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for making custom permutations of graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_graph_nodes(G, permutation_map):\n",
    "    \"\"\"\n",
    "    Returns a new graph with nodes relabeled according to the given permutation map.\n",
    "\n",
    "    Parameters:\n",
    "    G: networkx.Graph \n",
    "        The selected graph to permute\n",
    "    permutation_map: dict \n",
    "        Mapping from old node labels to new ones\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph \n",
    "        The permuted graph\n",
    "    \"\"\"\n",
    "    return nx.relabel_nodes(G, permutation_map, copy=True)\n",
    "\n",
    "\n",
    "# Custom permutations - some examples. Feel free to create your own.\n",
    "cyclic_map_1 = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 0} # Note: these two only work for n_nodes = 7\n",
    "cyclic_map_2 = {0: 2, 1: 3, 2: 4, 3: 5, 4: 6, 5: 0, 6: 1} # Change the indices to go up to n_nodes - 1 for this to work properly\n",
    "c_perm_map_1 = {0: 2, 2: 4, 4: 0}\n",
    "c_perm_map_2 = {1: 4, 4: 3, 3: 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate all permutations for n nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_permutation_maps(n_nodes):\n",
    "    \"\"\"\n",
    "    Generates a list of all unique node relabeling permutations for a graph with n_nodes. \n",
    "    Stores each permutation as a dictionary for use in permute_graph_nodes(G, permutation_map).\n",
    "    \n",
    "    Parameters:\n",
    "    n_nodes: int \n",
    "        Number of nodes in the graph.\n",
    "    \n",
    "    Returns:\n",
    "    perm_maps: list of dict \n",
    "        List of all permutation maps.\n",
    "    \"\"\"\n",
    "    node_labels = list(range(n_nodes))\n",
    "    perm_maps = []\n",
    "\n",
    "    for i, perm in enumerate(itertools.permutations(node_labels)):\n",
    "        perm_map = {old: new for old, new in zip(node_labels, perm)}\n",
    "        perm_maps.append(perm_map)\n",
    "\n",
    "    print(f\"{len(perm_maps)} permutations generated and saved as perm_maps[0] to perm_maps[{len(perm_maps)-1}]\")\n",
    "    return perm_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040 permutations generated and saved as perm_maps[0] to perm_maps[5039]\n"
     ]
    }
   ],
   "source": [
    "all_permutations = generate_all_permutation_maps(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom graphs\n",
    "custom_graphs = [\n",
    "    *[permute_graph_nodes(connected_graphs_n[2], perm) for perm in all_permutations],\n",
    "    *[permute_graph_nodes(connected_graphs_n[3], perm) for perm in all_permutations],\n",
    "    permute_graph_nodes(connected_graphs_n[4],c_perm_map_2)\n",
    "]\n",
    "custom_labels = [\n",
    "    *[f\"G3 with permutation #{i}: {all_permutations[i]}\" for i in range(len(all_permutations))],\n",
    "    *[f\"G4 with permutation #{i}: {all_permutations[i]}\" for i in range(len(all_permutations))],\n",
    "    f\"G5 with permutation {c_perm_map_2}\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for finding identical distributions at custom theta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_identical_distributions_at_theta_values(\n",
    "    connected_graphs_n = connected_graphs_n,\n",
    "    graph_labels = graph_labels,\n",
    "    theta_values = [np.pi/3, np.pi/6], \n",
    "    metric = tvd,\n",
    "    similarity_tolerance=0.02,\n",
    "    identity_tolerance=1e-5,\n",
    "    custom_graphs=None,\n",
    "    custom_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates IQP circuit distributions for all graphs at specified theta values\n",
    "    and compares them pairwise using total variation distance.\n",
    "\n",
    "    - Graph pairs with distance < identity_tolerance are classified as \"identical\".\n",
    "    - Graph pairs with distance < similarity_tolerance but > identity_tolerance\n",
    "      are classified as \"similar\".\n",
    "    - Graph pairs with distance >= similarity_tolerance are classified as \"different\".\n",
    "    - Special handling is applied for graphs whose labels indicate permutations.\n",
    "\n",
    "    Parameters:\n",
    "    connected_graphs_n : list of nx.Graph\n",
    "        List of connected graphs with n nodes.\n",
    "    target_theta_values : list of float\n",
    "        Theta values at which to simulate and compare distributions (default: [np.pi/3, np.pi/6]).\n",
    "    metric : callable\n",
    "        A function to compute the distance between two distributions (default: tvd).\n",
    "        (Expected signature: metric(dist1, dist2) -> float).\n",
    "    graph_labels : list of str\n",
    "        Labels for the graphs in connected_graphs_n.\n",
    "    similarity_tolerance : float, optional\n",
    "        Threshold below which graphs are considered \"similar\" (default: 0.02).\n",
    "    identity_tolerance : float, optional\n",
    "        Threshold below which graphs are considered \"identical\" (default: 1e-5).\n",
    "    custom_graphs : list of nx.Graph, optional\n",
    "        Additional user-supplied graphs to include in the comparison.\n",
    "    custom_labels : list of str, optional\n",
    "        Labels for custom_graphs. If None, defaults to \"custom_i\".\n",
    "\n",
    "    Returns:\n",
    "    identical : list of tuple\n",
    "        Pairs of graphs that are identical (indices, metric comparison result).\n",
    "    similar : list of tuple\n",
    "        Pairs of graphs that are similar but not identical (indices, metric comparison result).\n",
    "    different : list of tuple\n",
    "        Pairs of graphs that are distinguishable (indices, metric comparison result).\n",
    "    permutation_matches : list of tuple\n",
    "        Pairs of graphs marked as identical but one is a permutation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine connected and custom graphs\n",
    "    if custom_graphs is None:\n",
    "        all_graphs = connected_graphs_n\n",
    "        all_labels = graph_labels\n",
    "    else:\n",
    "        all_graphs = custom_graphs + connected_graphs_n\n",
    "        all_labels = (custom_labels if custom_labels else [f\"custom_{i}\" for i in range(len(custom_graphs))]) + graph_labels\n",
    "\n",
    "    num_graphs = len(all_graphs)\n",
    "\n",
    "    for theta in theta_values:\n",
    "        print(f\"\\nSimulating all graphs at theta = {theta}...\")\n",
    "\n",
    "        # Simulate probability distributions for each graph at this theta\n",
    "        theta_distributions = [\n",
    "            np.array(simulate_circuit(G, theta), dtype=float)\n",
    "            for G in all_graphs\n",
    "        ]\n",
    "\n",
    "        # Containers for classification results\n",
    "        identical = []\n",
    "        similar = []\n",
    "        different = []\n",
    "        permutation_matches = []\n",
    "\n",
    "        # Pairwise comparisons between all graph distributions\n",
    "        for i, j in combinations(range(num_graphs), 2):\n",
    "            d1 = theta_distributions[i]\n",
    "            d2 = theta_distributions[j]\n",
    "            metric_comparison = metric(d1, d2)\n",
    "\n",
    "            label_i = all_labels[i]\n",
    "            label_j = all_labels[j]\n",
    "\n",
    "            if metric_comparison < identity_tolerance:\n",
    "                # Treat permutation-labeled graphs separately\n",
    "                if (\"with permutation\" in label_i) or (\"with permutation\" in label_j):\n",
    "                    permutation_matches.append((i, j, metric_comparison))\n",
    "                else:\n",
    "                    identical.append((i, j, metric_comparison))\n",
    "            elif metric_comparison < similarity_tolerance:\n",
    "                similar.append((i, j, metric_comparison))\n",
    "            else:\n",
    "                different.append((i, j, metric_comparison))\n",
    "\n",
    "        # Printing results\n",
    "        print(f\"\\nResults for θ = {theta}:\")\n",
    "\n",
    "        if identical:\n",
    "            for i, j, d in identical:\n",
    "                print(f\" {all_labels[i]} ≡ {all_labels[j]} (TVD = {d:.2e})\")\n",
    "            print(f\"{len(identical)} Identical, non-permuted graph pairs (Distance < {identity_tolerance})\")\n",
    "        else:\n",
    "            print(\"No identical pairs.\")\n",
    "\n",
    "        print(f\"{len(permutation_matches)} Identical G1-permutation matches\")\n",
    "\n",
    "        if similar:\n",
    "            print(f\"{len(similar)} Similar graph pairs (Distance < {similarity_tolerance}):\")\n",
    "            for i, j, d in similar:\n",
    "                print(f\"  {all_labels[i]} ~ {all_labels[j]}  (TVD = {d:.2e})\")\n",
    "        else:\n",
    "            print(f\"No similar pairs (i.e., pairs with nonzero distance < {similarity_tolerance}).\")\n",
    "\n",
    "        if not identical and not similar:\n",
    "            print(f\"All graphs are distinguishable for this theta within a tolerance of {similarity_tolerance}.\")\n",
    "\n",
    "        # Visualization of identical graph pairs\n",
    "        n_nodes = all_graphs[0].number_of_nodes()\n",
    "        bitstrings = [format(k, f'0{n_nodes}b') for k in range(2**n_nodes)]\n",
    "\n",
    "        for i, j, _ in identical:\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "            nx.draw(all_graphs[i], ax=axes[0], with_labels=True, node_color='lightblue')\n",
    "            axes[0].set_title(f\"Graph {all_labels[i]}\")\n",
    "\n",
    "            nx.draw(all_graphs[j], ax=axes[1], with_labels=True, node_color='lightgreen')\n",
    "            axes[1].set_title(f\"Graph {all_labels[j]}\")\n",
    "\n",
    "            axes[2].bar(bitstrings, theta_distributions[i])\n",
    "            axes[2].set_title(\"Identical Distribution\")\n",
    "            axes[2].set_xlabel(\"Bitstring\")\n",
    "            axes[2].set_ylabel(\"Probability\")\n",
    "            axes[2].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "            plt.suptitle(f\"Identical graphs at theta = {theta}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare graphs and their isomorphisms using tvd \n",
    "\n",
    "# Uncomment to run\n",
    "#find_identical_distributions_at_theta_values(custom_graphs=custom_graphs,custom_labels=custom_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for checking the hamming weight and multiplicities for graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_graphs_by_amplitudes_and_hamming_weight(\n",
    "    custom_graphs=None,\n",
    "    custom_labels=None,\n",
    "    selected_indices=None,\n",
    "    graph_labels=graph_labels,\n",
    "    connected_graphs_n=connected_graphs_n,\n",
    "    theta_values=[np.pi/3, np.pi/6],\n",
    "    n_nodes=n_nodes,\n",
    "    compare_all=False,\n",
    "    tolerance = 0.002\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates IQP distributions for thetas in theta_values on selected or all graphs,\n",
    "    checks Hamming weight distributions and amplitude multiplicities.\n",
    "    Checks matches for each theta value and then for all theta values.\n",
    "\n",
    "    - If multiplicities differ => graphs are definitely non-isomorphic.\n",
    "    - If multiplicities match => graphs could be isomorphic.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    custom_graphs : list of nx.Graph\n",
    "        Custom graphs to include.\n",
    "    custom_labels : list of str\n",
    "        Labels for custom graphs.\n",
    "    selected_indices : list of int\n",
    "        Indices of graphs from connected_graphs_n to include (ignored if compare_all=True).\n",
    "    graph_labels : list of str\n",
    "        Labels for connected_graphs_n.\n",
    "    connected_graphs_n : list of nx.Graph\n",
    "        Set of connected graphs with n nodes.\n",
    "    theta_values : list of numpy expressions\n",
    "        Theta values to test (default: [pi/3, pi/6]).\n",
    "    n_nodes : int\n",
    "        Number of nodes in the graphs.\n",
    "    compare_all : bool\n",
    "        If True, compares all graphs in connected_graphs_n + custom_graphs.\n",
    "    tolerance : float\n",
    "        The tolerance for a probability value to count as non-zero\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for theta in theta_values:\n",
    "\n",
    "        # Collect graphs and labels\n",
    "        all_graphs, all_labels = [], []\n",
    "\n",
    "        if custom_graphs:\n",
    "            all_graphs.extend(custom_graphs)\n",
    "            all_labels.extend(custom_labels if custom_labels else [f\"custom_{i}\" for i in range(len(custom_graphs))])\n",
    "\n",
    "        if connected_graphs_n and graph_labels:\n",
    "            if compare_all:\n",
    "                all_graphs.extend(connected_graphs_n)\n",
    "                all_labels.extend(graph_labels)\n",
    "            elif selected_indices:\n",
    "                for idx in selected_indices:\n",
    "                    all_graphs.append(connected_graphs_n[idx])\n",
    "                    all_labels.append(graph_labels[idx])\n",
    "\n",
    "        if not all_graphs:\n",
    "            raise ValueError(\"No graphs selected.\")\n",
    "\n",
    "        # Simulate distributions\n",
    "        theta_distributions = [\n",
    "            np.array(simulate_circuit(G, theta), dtype=float)\n",
    "            for G in all_graphs\n",
    "        ]\n",
    "\n",
    "        # Hamming weight distribution + multiplicities\n",
    "\n",
    "        bitstrings = [format(k, f'0{n_nodes}b') for k in range(2**n_nodes)]\n",
    "        hamming_weights = [bs.count(\"1\") for bs in bitstrings]\n",
    "        summary = {}\n",
    "        for label, dist in zip(all_labels, theta_distributions):\n",
    "            hw_dict = defaultdict(list)\n",
    "            for bs, hw, p in zip(bitstrings, hamming_weights, dist):\n",
    "                if p > tolerance:  # ignore values smaller than the tolerace\n",
    "                    hw_dict[hw].append(round(p, 10))  # round to remove noise\n",
    "\n",
    "            multiplicities = {hw: Counter(vals) for hw, vals in hw_dict.items()}\n",
    "            summary[label] = {\n",
    "                \"hamming_weight_distribution\": {hw: sum(hw_dict[hw]) for hw in hw_dict},\n",
    "                \"multiplicities\": multiplicities\n",
    "            }\n",
    "\n",
    "        # Compare graphs by multiplicities\n",
    "        print(f\"\\nMultiplicity Comparison at theta = {theta}\")\n",
    "        labels = list(summary.keys())\n",
    "        matching_pairs = []\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(i+1, len(labels)):\n",
    "                mult1 = summary[labels[i]][\"multiplicities\"]\n",
    "                mult2 = summary[labels[j]][\"multiplicities\"]\n",
    "                if mult1 == mult2:\n",
    "                    print(f\"{labels[i]} vs {labels[j]}: multiplicities match => could be isomorphic\")\n",
    "                    matching_pairs.append((labels[i], labels[j]))\n",
    "\n",
    "        results[theta] = {\n",
    "            \"summary\": summary,\n",
    "            \"matching_pairs\": set(matching_pairs)  # store as set for easy intersection later\n",
    "        }\n",
    "\n",
    "    # Find pairs that matched across all thetas\n",
    "    if results:\n",
    "        common_pairs = set.intersection(*(results[theta][\"matching_pairs\"] for theta in theta_values))\n",
    "        print(\"\\nGraphs that are isomorphic across all theta values:\")\n",
    "        if common_pairs:\n",
    "            for pair in common_pairs:\n",
    "                print(f\"{pair[0]} vs {pair[1]}\")\n",
    "        else:\n",
    "            print(\"No graph pairs matched across all theta values.\")\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiplicity Comparison at theta = 1.0471975511965976\n",
      "G_43 vs G_91: multiplicities match => could be isomorphic\n",
      "G_108 vs G_110: multiplicities match => could be isomorphic\n",
      "G_129 vs G_142: multiplicities match => could be isomorphic\n",
      "G_151 vs G_234: multiplicities match => could be isomorphic\n",
      "G_313 vs G_363: multiplicities match => could be isomorphic\n",
      "G_330 vs G_368: multiplicities match => could be isomorphic\n",
      "G_344 vs G_501: multiplicities match => could be isomorphic\n",
      "G_382 vs G_418: multiplicities match => could be isomorphic\n",
      "\n",
      "Multiplicity Comparison at theta = 0.5235987755982988\n",
      "\n",
      "Graphs that are isomorphic across all theta values:\n",
      "No graph pairs matched across all theta values.\n"
     ]
    }
   ],
   "source": [
    "compare_graphs_by_amplitudes_and_hamming_weight(compare_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version of the function used for looking at specific graphs with plotting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting function\n",
    "def compare_plot_graphs_by_amplitudes_and_hamming_weight(\n",
    "    custom_graphs=None,\n",
    "    custom_labels=None,\n",
    "    selected_indices=None,\n",
    "    graph_labels=graph_labels,\n",
    "    connected_graphs_n=connected_graphs_n,\n",
    "    theta_values=[np.pi/3, np.pi/6],\n",
    "    n_nodes=n_nodes\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates IQP distributions for thetas in theta_values on selected or all graphs,\n",
    "    checks Hamming weight distributions and amplitude multiplicities.\n",
    "    Checks matches for each theta value.\n",
    "    Plots the network x graphs, their distributions at each theta value and their Hamming weights.\n",
    "\n",
    "    - If multiplicities differ => graphs are definitely non-isomorphic.\n",
    "    - If multiplicities match => graphs could be isomorphic.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    custom_graphs : list of nx.Graph\n",
    "        Custom graphs to include.\n",
    "    custom_labels : list of str\n",
    "        Labels for custom graphs.\n",
    "    selected_indices : list of int\n",
    "        Indices of graphs from connected_graphs_n to include (ignored if compare_all=True).\n",
    "    graph_labels : list of str\n",
    "        Labels for connected_graphs_n.\n",
    "    connected_graphs_n : list of nx.Graph\n",
    "        Set of connected graphs with n nodes.\n",
    "    theta_values : list of numpy expressions\n",
    "        Theta values to test (default: [pi/3, pi/6]).\n",
    "    n_nodes : int\n",
    "        Number of nodes in the graphs.\n",
    "    \"\"\"\n",
    "\n",
    "    for theta in theta_values:\n",
    "\n",
    "        # --- Collect graphs and labels\n",
    "        all_graphs, all_labels = [], []\n",
    "        if custom_graphs:\n",
    "            all_graphs.extend(custom_graphs)\n",
    "            all_labels.extend(custom_labels if custom_labels else [f\"custom_{i}\" for i in range(len(custom_graphs))])\n",
    "        if selected_indices and connected_graphs_n and graph_labels:\n",
    "            for idx in selected_indices:\n",
    "                all_graphs.append(connected_graphs_n[idx])\n",
    "                all_labels.append(graph_labels[idx])\n",
    "        if not all_graphs:\n",
    "            raise ValueError(\"No graphs selected.\")\n",
    "\n",
    "        \n",
    "        # --- Simulate distributions\n",
    "        raw_distributions = [\n",
    "            np.array(simulate_circuit(G, theta), dtype=float)\n",
    "            for G in all_graphs\n",
    "        ]\n",
    "\n",
    "        bitstrings = [format(k, f'0{n_nodes}b') for k in range(2**n_nodes)]\n",
    "        hamming_weights = [bs.count(\"1\") for bs in bitstrings]\n",
    "\n",
    "        # Hamming weight distribution + multiplicities\n",
    "        summary = {}\n",
    "        for label, dist in zip(all_labels, raw_distributions):\n",
    "            hw_dict = defaultdict(list)\n",
    "            for bs, hw, p in zip(bitstrings, hamming_weights, dist):\n",
    "                if p > 1e-12:  # ignore exact zeros\n",
    "                    hw_dict[hw].append(round(p, 10))  # round to remove noise\n",
    "\n",
    "            multiplicities = {hw: Counter(vals) for hw, vals in hw_dict.items()}\n",
    "            summary[label] = {\n",
    "                \"hamming_weight_distribution\": {hw: sum(hw_dict[hw]) for hw in hw_dict},\n",
    "                \"multiplicities\": multiplicities\n",
    "            }\n",
    "\n",
    "        # Check isomorphism candidates\n",
    "        print(\"=== Multiplicity Comparison ===\")\n",
    "        labels = list(summary.keys())\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(i+1, len(labels)):\n",
    "                mult1 = summary[labels[i]][\"multiplicities\"]\n",
    "                mult2 = summary[labels[j]][\"multiplicities\"]\n",
    "                if mult1 == mult2:\n",
    "                    print(f\"{labels[i]} vs {labels[j]}: multiplicities match => could be isomorphic\")\n",
    "                else:\n",
    "                    print(f\"{labels[i]} vs {labels[j]}: multiplicities differ => non-isomorphic\")\n",
    "\n",
    "        # Plotting\n",
    "        num_graphs = len(all_graphs)\n",
    "        fig = plt.figure(figsize=(max(20, 3*num_graphs), 12))\n",
    "        gs = GridSpec(3, num_graphs, height_ratios=[1, 1.5, 1], hspace=0.6, wspace=0.4)\n",
    "\n",
    "        # Top row: nx graph plots\n",
    "        for i, (graph, label) in enumerate(zip(all_graphs, all_labels)):\n",
    "            ax_graph = fig.add_subplot(gs[0, i])\n",
    "            pos = nx.spring_layout(graph, seed=42) if len(graph.nodes()) <= 6 else nx.circular_layout(graph)\n",
    "            nx.draw(graph, pos, ax=ax_graph,\n",
    "                    with_labels=True, node_color=\"lightblue\", node_size=400,\n",
    "                    font_size=8, font_weight=\"bold\", edge_color=\"gray\")\n",
    "            ax_graph.set_title(label, fontsize=8, fontweight=\"bold\")\n",
    "            ax_graph.axis(\"off\")\n",
    "\n",
    "        # Middle row: probability distributions\n",
    "        ax_bar = fig.add_subplot(gs[1, :])\n",
    "        x = np.arange(len(bitstrings))\n",
    "        width = 0.8 / len(all_graphs)\n",
    "\n",
    "        # Make graphs have distinct colours\n",
    "        cmap = plt.colormaps['hsv']\n",
    "        indices = bit_reversed_indices(len(all_graphs))\n",
    "        colors = [cmap(i / len(all_graphs)) for i in indices]\n",
    "\n",
    "        for i, (dist, label) in enumerate(zip(raw_distributions, all_labels)):\n",
    "            ax_bar.bar(x + i*width, dist, width=width, label=label, color=colors[i])\n",
    "        ax_bar.set_xticks(x + width*(len(all_graphs)-1)/2)\n",
    "        ax_bar.set_xticklabels(bitstrings, rotation=90)\n",
    "        ax_bar.set_ylabel(\"Probability\")\n",
    "        ax_bar.set_xlabel(\"Bitstring\")\n",
    "        ax_bar.set_title(f\"Graph distributions at theta = {theta}\")\n",
    "        ax_bar.legend(loc=\"upper right\", fontsize=\"small\")\n",
    "\n",
    "        # Bottom row: Hamming weight summary\n",
    "        for i, label in enumerate(all_labels):\n",
    "            ax_hw = fig.add_subplot(gs[2, i])\n",
    "            hw_dist = summary[label][\"hamming_weight_distribution\"]\n",
    "            ax_hw.bar(hw_dist.keys(), hw_dist.values(), color=colors[i])\n",
    "            ax_hw.set_title(f\"Hamming Weights\\n{label}\", fontsize=8)\n",
    "            ax_hw.set_xlabel(\"Hamming Weight\")\n",
    "            ax_hw.set_ylabel(\"Total Prob.\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot\n",
    "\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[42,90,107,109])\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[128,141,150,233])\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[312,362,329,367])\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[343,500,381,417])\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[153,265])\n",
    "#compare_plot_graphs_by_amplitudes_and_hamming_weight(selected_indices=[13,17])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
